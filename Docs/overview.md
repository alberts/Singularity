## Requests vs Deploys vs Tasks

A Request in Singularity is the top-level API object and defines high-level metadata about a particular type of task to run. It is similar to the idea of a project or class in an OO system. It has a history and can contain many deploys and tasks (although only one active and pending deploy at any one time). Tasks are the actual running implementations (processes started by a Mesos executor) of Requests - for instance, a task runs on a particular slave and has a directory and logs. However, each task must be part of a Deploy. The Deploy object defines the specific command that should be executed by the tasks. There can be many tasks running for a single Deploy/Request (defined by the instances field on a Request). If a task dies, a new task will take its place. The Request and Deploy objects and their fields are not changed by Singularity and can only be updated by posting a new Request or Deploy. However, a Request has state about whether or not it is active vs paused and whether a particular Deploy is active or pending.

## Scheduled Requests (Cron Jobs)

Scheduled Requests in Singularity currently support standard unix cron schedules with the addition of an optional seconds parameter (at the beginning). Singularity will run these Requests on the specified schedule forever. There is one notable difference between execution of scheduled tasks inside of Singularity and that of a normal crontab: Singularity will only run a single instance of a given scheduled Request at a time. This has implications for when Singularity should schedule a Request after it completes. In standard cron, a new task would be spawned every single time the cron schedule matched. In Singularity, tasks are scheduled initially based on current time, and then scheduled afterwords based on the start time of the previously executed task. For example, if a task is scheduled to run every 5 minutes, but always takes 6 minutes to run, it will essentially always be executing. Furthermore, if a task is scheduled to run at 1pm everyday, and takes just over 24 hours, it will also always be running. An important thing to note is because each new task is scheduled based on the start time of the previous task, there is not an accumulation of debt (beyond a single task.) Scheduled tasks can also be retried on failures, which is useful if a task runs infrequently but should always complete successfully. This is enabled by setting a field on the Request object, numRetriesOnFailure (default is 0), to the number of times Singularity should instantly retry a failed scheduled task. Scheduled tasks can also be ran immediately via the API and UI. Cron schedules are defined using the standard unix cron format, but may be slightly modified to fit into Quartz cron expressions, which are defined [here](http://quartz-scheduler.org/api/2.1.0/org/quartz/CronExpression.html)

## Features

#### Deployments
Singularity has the notion of an active and pending deploy for a given Request. After a new deploy is posted, it is pending until the tasks for that deploy are fully realized and pass healthchecks (if specified.) Singularity, at the very least, will wait until tasks get to task state TASK_RUNNING. When a new deploy is deemed healthy, it becomes the active deploy, and any previous active deploy's tasks are killed. If a deployment fails, the new tasks are killed and the active deploy does not change.

#### Fault Tolerance
Singularity will detect when tasks finish, are killed, or are lost (due to hardware failure) and will start those tasks on new slaves. (See Scheduled Requests for information about exiting scheduled tasks.) If Singularity crashes or is exited, tasks it launched will continue to execute and will be recognized when a Singularity leader reregisters with Mesos. Singularity can send email notifications to Request owners when their tasks are killed or lost. Singularity can also place tasks that are failing often into a system cooldown in order to protect cluster resources. This protects Singularity and Mesos from constantly attempting to execute a failing task and clogging logs and consuming resource offers.

#### Load Balancer API
Singularity supports integration with a [Load Balancer API](lbs.md). Singularity will keep the load balancer informed of task deploys and failures.

#### Rack Awareness
Singularity Request's support a rackSensitive property. If set to true, Singularity will attempt to evenly distribute tasks of a particular Request between racks. Additionally, Singularity will not run multiple tasks of the same rackSensitive Request on the same slave.

#### Bounce Request, Kill Task
Singularity provides an API and UI for bouncing a Request or killing an individual task. When a Request is bounced, it will temporarily oversubscribe that Request, launching new instances and waiting until new tasks are healthy before killing old tasks. When a task is killed, it will be immediately killed inside Mesos but Singularity will attempt to launch a new task to take its place.

#### Decomissioning Slaves and Racks
Singularity allows slaves and/or racks to be decommissioned. Singularity attempts to keep in sync with Mesos by keeping its own list of slaves and updating this as it sees new resource offers from new slaves or Mesos notifies Singularity that a particular slave has been killed. Singularity can decommission a slave or rack which will prevent future tasks from executing on it as well as oversubscribing all Requests which are executing on that slave/rack. Similar to a Request bounce, Singularity will wait for new tasks to become healthy before killing old tasks executing on decommissioning racks and slaves.

## Design

Singularity uses ZooKeeper and MySQL to maintain state and primarily uses ZooKeeper to keep track of a list of active Requests and the current tasks that fulfill these Requests. MySQL is used to store the history of edits to Requests and the task history of any launched tasks. Singularity dumps information from ZooKeeper into MySQL periodically, but only relies on MySQL for a very small number of operational concerns. Singularity uses leader election in ZooKeeper to maintain a single leader which is capable of registering with the Mesos master; other Singularity nodes may handle web requests but do not interact directly with Mesos. Because of the ability for other nodes to edit state, Singularity often uses queues which are consumed by the Singularity leader to effect changes in Mesos. 

The Singularity leader uses a simple lock to ensure only a single Mesos API call is handled concurrently. This simplifies the processing of state inside of Singularity but also implies that operations which want to make API calls into Mesos or change state often must also acquire this lock. This is accomplished by adding operations to queues which are consumed by threads which periodically acquire this lock in order to process changes.

Singularity requires ZooKeeper in order to operate. Singularity will abort and essentially call <code>System.exit()</code> when it detects failures talking to ZooKeeper. Therefore, Singularity should always run with multiple instances and in an environment where it will restart on failure (for example, using Monit.) When Singularity comes back up and is elected leader, it talks to Mesos in order to reconcile state. Tasks which were running when Singularity exited will continue to run unless they finish or there is a hardware failure. Scheduled tasks that are due will not run while Singularity is not running, but will be executed upon successful startup.
